### This is my custom LinearRegression ğŸ˜

ì„¤ëª…
------------
1. ë¨¼ì € í•™ìŠµì„ ì‹œì‘í•˜ê¸° ì „ì— ë°ì´í„°ë“¤ì„ ì „ì²˜ë¦¬í•œë‹¤. (preprocessing)
- x ê°’ì´ ë¹„ìŠ·í•œ y ê°’ë“¤ë¼ë¦¬ì˜ í‰ê· ê°’ì„ êµ¬í•œë‹¤.  
``` python
self.data = list(zip(X, y))
self.data = np.sort(self.data)
self.data = pd.DataFrame(self.data, columns=["X", "y"])

def duplicate(x):
    duplicate_data = self.data[(self.data["X"] > (x - 0.1)) & (self.data["X"] < (x + 0.1))]["y"]
    return sum(duplicate_data) / len(duplicate_data)

self.data["y"] = self.data["X"].apply(lambda x: duplicate(x))
self.data = self.data.drop_duplicates(["y"], keep="first")
self.data = self.data.reset_index(drop=True)
```

2. ì „ì²˜ë¦¬í•œ ë°ì´í„°ì—ì„œ up_rate ì„ ê¸°ì¤€ìœ¼ë¡œ ì¦ê°€ëŸ‰ì„ ì¸¡ì •í•˜ì—¬ ì¦ê°€ëŸ‰ì˜ í‰ê· ì„ êµ¬í•œë‹¤.
- ì¦ê°€ëŸ‰ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤.
``` python
for i in range(self.data.shape[0]):
    try:
        up.append((self.data.iloc[i, 1] - self.data.iloc[i + self.uprate, 1]) / (
                self.data.iloc[i, 0] - self.data.iloc[i + self.uprate, 0]))
    except:
        pass

for i in reversed(range(self.data.shape[0])):
    try:
        up.append((self.data.iloc[i, 1] - self.data.iloc[i - self.uprate, 1]) / (
                self.data.iloc[i, 0] - self.data.iloc[i - self.uprate, 0]))
    except:
        pass

# ê¸°ìš¸ê¸° êµ¬í•˜ê¸°
self.a = sum(up) / len(up)
```


3. ì ˆí¸ì€ ì²«ë²ˆì§¸ x ê°’ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ - ì²«ë²ˆì§¸ x ê°’ì— ëŒ€í•œ y ê°’ ì„ í•˜ì—¬ êµ¬í•  ìˆ˜ ìˆë‹¤.  
``` python
# ì ˆí¸ êµ¬í•˜ê¸°
self.b = self.data.iloc[0, 1] - (self.a * self.data.iloc[0, 0])
```

ê·¸ë ‡ê²Œ y = ax + b í˜•íƒœì˜ ì¼ì°¨í•¨ìˆ˜(LinearRegression) ê·¸ë˜í”„ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.
``` python
# ì •ë³´
def info(self, ifpr=True):
    if ifpr:
        print(f"y = {self.a}x + ({self.b})")
    return self.a, self.b
```

4. X ê°’ê³¼ y ê°’ìœ¼ë¡œ í‰ê°€ ê·¸ë˜í”„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.
``` python
def evaluation_graph(self, X, y):
    plt.scatter(X, y, label="original")
    plt.scatter(self.data.iloc[:, 0], self.data.iloc[:, 1], color="red", label="preprocessing")

    pred = self.predict(self.data.iloc[:, 0])
    plt.plot(self.data.iloc[:, 0], pred, color="yellow", label="predict")

    plt.legend()

    plt.show()
```

<div>
<img width="285" alt="evaluation_graph_img" src="https://user-images.githubusercontent.com/66504341/103880075-ff0de680-511b-11eb-8d5c-d9ba8cf9c559.PNG">
</div>

5. ì˜ˆì¸¡ì€ predict ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ í•  ìˆ˜ ìˆë‹¤.
``` python
# ì˜ˆì¸¡
def predict(self, X):
    y_pred = []
    for i in X:
        y_pred.append(self.a * i + self.b)
    return y_pred
```

  
ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤
--------------------

``` python
# ì„í¬íŠ¸
from CustomML.CustomRegression import CustomLinearRegression

# ìƒì„±
lr_model = CustomLinearRegression()

# í•™ìŠµ
lr_model.fit(heights, weights)

# ì‹¤ì œ ê°’ì˜ ë¶„í¬ì™€ ì„ í˜•íšŒê·€ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„.
lr_model.evaluation_graph(heights, weights)
```

ì „ì²´ì½”ë“œ
-----------

``` python
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


class CustomLinearRegression():
    def __init__(self, up_rate=10):
        self.a = 0  # ê¸°ìš¸ê¸°
        self.b = 0  # y ì ˆí¸
        self.data = None  # X, y ë°ì´í„°í”„ë ˆì„
        self.uprate = up_rate  # ì¦ê°€ëŸ‰ 

    def fit(self, X=None, y=None):
        if X is None or y is None:
            raise Exception("x and y cannot be None.")
        if not isinstance(X, np.ndarray) or not isinstance(y, np.ndarray):
            raise Exception("X and y should be ndarray")
        if len(X) != len(y):
            raise Exception("X length and y length cannot be different")
        self.fit_logic(X, y)

    # í•™ìŠµ
    def fit_logic(self, X, y):
        up = []  # ë°ì´í„°ë§ˆë‹¤ ì¦ê°€ëŸ‰ì— ë”°ë¥¸ ê¸°ìš¸ê¸°ë¥¼ ë‹´ëŠ” ë¦¬ìŠ¤íŠ¸.

        self.data = list(zip(X, y))
        self.data = np.sort(self.data)
        self.data = pd.DataFrame(self.data, columns=["X", "y"])

        def duplicate(x):
            duplicate_data = self.data[(self.data["X"] > (x - 0.1)) & (self.data["X"] < (x + 0.1))]["y"]
            return sum(duplicate_data) / len(duplicate_data)

        self.data["y"] = self.data["X"].apply(lambda x: duplicate(x))
        self.data = self.data.drop_duplicates(["y"], keep="first")
        self.data = self.data.reset_index(drop=True)

        for i in range(self.data.shape[0]):
            try:
                up.append((self.data.iloc[i, 1] - self.data.iloc[i + self.uprate, 1]) / (
                        self.data.iloc[i, 0] - self.data.iloc[i + self.uprate, 0]))
            except:
                pass

        for i in reversed(range(self.data.shape[0])):
            try:
                up.append((self.data.iloc[i, 1] - self.data.iloc[i - self.uprate, 1]) / (
                        self.data.iloc[i, 0] - self.data.iloc[i - self.uprate, 0]))
            except:
                pass

        # ê¸°ìš¸ê¸° êµ¬í•˜ê¸°
        self.a = sum(up) / len(up)

        # ì ˆí¸ êµ¬í•˜ê¸°
        self.b = self.data.iloc[0, 1] - (self.a * self.data.iloc[0, 0])

    # ì˜ˆì¸¡
    def predict(self, X):
        y_pred = []
        for i in X:
            y_pred.append(self.a * i + self.b)
        return y_pred

    # ì •ë³´
    def info(self, ifpr=True):
        if ifpr:
            print(f"y = {self.a}x + ({self.b})")
        return self.a, self.b

    def evaluation_graph(self, X, y):
        plt.scatter(X, y, label="original")
        plt.scatter(self.data.iloc[:, 0], self.data.iloc[:, 1], color="red", label="preprocessing")

        pred = self.predict(self.data.iloc[:, 0])
        plt.plot(self.data.iloc[:, 0], pred, color="yellow", label="predict")

        plt.legend()

        plt.show()
```

